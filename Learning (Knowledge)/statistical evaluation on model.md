#statistika 
It involves various statistical metrics and tests to quantitatively measure how well the model performs.
✅**Accuracy-** Accuracy measures the proportion of correctly classified instances in a classification model.
✅**Mean Absolute Error (MAE)-** MAE measures the average absolute difference between the predicted values and the actual values.
✅**Mean Squared Error (MSE)-** MSE calculates the average of the squared differences between predicted and actual values.
✅**Root Mean Squared Error (RMSE)**- RMSE is the square root of MSE, providing an interpretable metric in the same units as the target variable.
✅**R-squared (R²) or Coefficient of Determination**- R² measures the proportion of the variance in the dependent variable that is explained by the independent variables in the model.
✅**Area Under the Receiver Operating Characteristic (ROC AUC)-** It measures the area under the receiver operating characteristic curve, which plots the trade-off between true positive rate (recall) and false positive rate at various thresholds.
✅**Confusion Matrix-** A table that shows the number of true positives, true negatives, false positives, and false negatives, providin detailed insights into the performance of a classification model.
✅**Precision-** Measures the ratio of true positive predictions to the total positive predictions, emphasizing the model’s ability to avoid false positives.
✅**Recall-** Measures the ratio of true positives to the total actual positives, emphasizing the model’s ability to find all relevant instances.
✅**F1-Score-** The harmonic mean of precision and recall, offering a balance between the two metrics.

# Feature Selection

It the Statistical techniques which guides in selection of relevant features (variables) for predictive modeling. Techniques like **feature importance** and **correlation analysis** help data scientists choose the most influential factors.

✅**Correlation-Based Feature Selection-** Selects features based on their correlation with the target variable, removing redundant or highly correlated features.

✅**Tree-Based Feature Importance-** Decision tree and ensemble models (e.g., Random Forest, Gradient Boosting) can provide feature importance scores, which can be used to select the most important features.

✅**Mutual Information-** Measures the dependency between features and the target variable, selecting features with high mutual information.

✅**L1 Regularization (Lasso)**- Encourages sparsity in the model by penalizing the absolute values of feature coefficients, effectively selecting a subset of features.
